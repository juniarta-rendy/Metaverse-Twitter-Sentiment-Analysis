{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0449a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import re\n",
    "import nltk\n",
    "import ast\n",
    "import string\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from datetime import datetime,timedelta\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Cleaning/Clean_Dataset.csv')\n",
    "jakarta = pytz.timezone('Asia/Jakarta')\n",
    "time_date = \"%m/%d/%Y %H:%M\"\n",
    "df['datetime_created'] = df['Datetime'].apply(lambda x:datetime.strptime(x,time_date))\n",
    "df['date_created'] = df['datetime_created'].apply(lambda x:x.date())\n",
    "df['time_created'] = df['datetime_created'].apply(lambda x:x.time())\n",
    "df = df.drop(['datetime_created'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367ee452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9ec99",
   "metadata": {},
   "source": [
    "### Additional Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae4001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7b9c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61984    @WabiSabiNFT @HELIX_Metaverse NANI?! @dummybeeean @God_of_Pekka @morisecosoluzi1\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df[df['Clean_Text'].isnull() == True]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f692a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "Datetime            0\n",
       "Tweet Id            0\n",
       "Text                0\n",
       "Username            0\n",
       "Location        28393\n",
       "Clean_Text          1\n",
       "language            0\n",
       "date_created        0\n",
       "time_created        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294cd43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id    36523\n",
       "no     8078\n",
       "en     6062\n",
       "et     2697\n",
       "af     2617\n",
       "sl     2587\n",
       "tl     1933\n",
       "nl     1464\n",
       "it     1401\n",
       "so     1369\n",
       "sq     1245\n",
       "sv     1181\n",
       "da     1116\n",
       "ca      936\n",
       "sw      921\n",
       "hr      908\n",
       "fi      831\n",
       "cy      830\n",
       "tr      743\n",
       "ro      627\n",
       "lt      399\n",
       "pl      344\n",
       "sk      267\n",
       "fr      162\n",
       "hu      145\n",
       "pt      130\n",
       "es      104\n",
       "cs       92\n",
       "lv       78\n",
       "vi       77\n",
       "de       73\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['language']!='in']['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e87d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate non-bahasa text to indonesian\n",
    "def trans(x,src):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        sentence = translator.translate(x,src=src,dest='id').text\n",
    "    except:\n",
    "        sentence = x\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b59a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text'] = df.apply(lambda x: trans(x['Clean_Text'],x['language']) if(x['language']!='in') else x['Clean_Text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = df['Clean_Text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "clean_text.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3e581",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_word(x, key_list):\n",
    "    n = len(key_list)\n",
    "    word_tokens = word_tokenize(x)\n",
    "    new_x = ''\n",
    "    for word in word_tokens:\n",
    "        if word not in key_list:\n",
    "            new_x = new_x+word+' '\n",
    "            return new_x\n",
    "def clean_tweets(text):\n",
    "    pass\n",
    "\n",
    "def count_words(x):\n",
    "    words = word_tokenize(x)\n",
    "    n=len(words)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b74a4b",
   "metadata": {},
   "source": [
    "### Word Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Word Dictionary\n",
    "word_dict = {}\n",
    "for i in range(0,len(df['Clean_Text'])):\n",
    "    sentence = df['Clean_Text'][i]\n",
    "    word_token = word_tokenize(sentence)\n",
    "    for j in word_token:\n",
    "        if j not in word_dict:\n",
    "            word_dict[j] = 1\n",
    "        else:\n",
    "            word_dict[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b50fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "len({k:v for (k,v) in word_dict.items() if v <4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62217056",
   "metadata": {},
   "source": [
    "# Import Lexicon Data\n",
    "##### sources:\n",
    "\n",
    "https://github.com/louisowen6/NLP_bahasa_resources\n",
    "https://github.com/abhimantramb/elang/blob/master/word2vec/utils/swear-words.txt\n",
    "https://github.com/fajri91/InSet\n",
    "https://github.com/agusmakmun/SentiStrengthID/blob/master/id_dict/sentimentword.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "negasi = ['bukan','tidak','ga','gk']\n",
    "lexicon = pd.read_csv('Lexicon Dictionary/modified_full_lexicon.csv')\n",
    "lexicon = lexicon.drop(lexicon[(lexicon['word'] == 'bukan')|\n",
    "                              (lexicon['word'] == 'tidak')|\n",
    "                              (lexicon['word'] == 'ga')|\n",
    "                              (lexicon['word'] == 'gk')].index,axis=0)\n",
    "lexicon = lexicon.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_word = lexicon['word'].to_list()\n",
    "lexicon_num_words = lexicon['number_of_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9151a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is words in dictionary that doesn't included in lexicon\n",
    "ns_words = []\n",
    "#create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "for word in word_dict.keys():\n",
    "    if word not in lexicon_word:\n",
    "        kata_dasar = stemmer.stem(word)\n",
    "        if kata_dasar not in lexicon_word:\n",
    "            ns_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look what kind of words they are, lets start with some words that have many occurences as this most likely not a type case\n",
    "len({ k:v for (k,v) in word_dict.items() if ((k in ns_words) & (v>3)) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8faa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_words_list = { k:v for (k,v) in word_dict.items() if ((k in ns_words) & (v>3)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the most occurences word descending\n",
    "sort_orders = sorted(ns_words_list.items(), key=lambda x: x[1], reverse = True)\n",
    "sort_orders = sort_orders[0:20]\n",
    "for i in sort_orders:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_plot = df['Clean_Text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978df2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_plot_1 = word_to_plot.apply(lambda x: del_word(x,negasi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7662834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a word cloud to see which words that appear often in tweets of metaverse\n",
    "wordcloud = Wordcloud(width = 800, height = 300, background_color = 'black', \n",
    "                      max_words = 1000, min_font_size = 20).generate(str(word_to_plot_1))\n",
    "#plot the word cloud\n",
    "fig = plt.figure(figsize = (8,8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54375de8",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
