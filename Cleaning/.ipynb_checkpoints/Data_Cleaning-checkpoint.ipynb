{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09c5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emot\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe99abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('Clean_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a744bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stopword remove\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "#create Stemmer\n",
    "Fact = StemmerFactory()\n",
    "Stemmer = Fact.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86112e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Dataset\n",
    "def clean_text(text):\n",
    "    #lowerCase\n",
    "    text = text.lower()\n",
    "    # Remove url\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)\n",
    "    # Remove hashtag\n",
    "    text = re.sub(r'#\\w+','',text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+','',text)\n",
    "    # Remove emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+','',text)\n",
    "    #remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    #stemming\n",
    "    text = Stemmer.stem(text)\n",
    "    #tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    words_filtered = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    text = ' '.join(words_filtered)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text'] = df['Text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language = 'id'\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the language detection function to the text column\n",
    "df['language'] = df['Text'].apply(lambda x: detect_language(x))\n",
    "\n",
    "# Filter the DataFrame to keep only rows in the target language\n",
    "#df = df[df['language'] == target_language]\n",
    "\n",
    "# Drop the language column\n",
    "#df.drop('language', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5377f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df.to_csv('Data_Clean+Language.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af055b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
